# Embedding Search System Configuration
# =====================================
# Copy this file to config.toml and customize as needed.
# You can also create project-specific configs as .embedrc or .embed/config.toml

# Chunking Configuration
# ======================

# Size of text chunks for embedding (number of lines)
# Smaller chunks provide more precise results but may miss context
# Larger chunks provide more context but may be less precise
chunk_size = 100

# Cache Configuration
# ===================

# Maximum number of embeddings to cache in memory
# Higher values use more memory but reduce computation time
embedding_cache_size = 10000

# Maximum number of search results to cache
# Caches recent search queries for faster repeated searches
search_cache_size = 100

# Directory for persistent cache files
# Will be created if it doesn't exist
cache_dir = ".embed_cache"

# Processing Configuration
# ========================

# Number of chunks to process in parallel batches
# Higher values can be faster but use more memory/CPU
batch_size = 32

# Storage Configuration
# =====================

# Path to the vector database directory
# Will be created if it doesn't exist
vector_db_path = ".embed_db"

# Git Watching Configuration
# ==========================

# Enable automatic file watching using git status
# When enabled, the system monitors for file changes
enable_git_watch = true

# How often to poll for git changes (in seconds)
# Lower values are more responsive but use more CPU
git_poll_interval_secs = 5

# Search Configuration
# ====================

# Include test files in indexing and search results
# Set to false to ignore files with test patterns (test_, _test, spec_, etc.)
include_test_files = false

# Maximum number of search results to return
# Higher values provide more comprehensive results but slower response
max_search_results = 20

# Enable ripgrep as fallback for text-based searching
# When vector search fails or returns few results, use ripgrep for keyword search
ripgrep_fallback = true

# Model Configuration
# ===================

# Name of the embedding model to use
# Current supported models:
# - "sentence-transformers/all-MiniLM-L6-v2" (default, fast, 384 dimensions)
# Note: Changing this requires rebuilding the entire index
model_name = "sentence-transformers/all-MiniLM-L6-v2"

# Dimensions of the embedding vectors
# Must match the model's output dimensions
# Nomic embeddings produce 768-dimensional embeddings
embedding_dimensions = 768

# Logging Configuration
# =====================

# Log level for the application
# Valid values: error, warn, info, debug, trace
# "info" provides balanced logging, "debug" shows detailed operation info
log_level = "info"

# Environment Variable Override Examples
# ======================================
# You can override any setting using environment variables with EMBED_ prefix:
#
# export EMBED_CHUNK_SIZE=150
# export EMBED_BATCH_SIZE=64  
# export EMBED_LOG_LEVEL=debug
# export EMBED_INCLUDE_TEST_FILES=true
# export EMBED_VECTOR_DB_PATH=/custom/path/.embed_db
#
# Boolean values: true/false
# Numbers: use decimal notation
# Strings: no quotes needed